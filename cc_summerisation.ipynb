{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = datasets.load_dataset('kreimben/leetcode_with_youtube_captions')['train']\n",
    "df = df.to_pandas()\n",
    "df.sample(3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "462de18ad09c9d6f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "example = df[df['id'] == 1]['cc_content']\n",
    "example.sample(3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bd7974093ce6c74",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "N = len(example)\n",
    "idx = random.randint(0, N)\n",
    "\n",
    "example_yt_cc = example.values[idx]\n",
    "example_yt_cc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32c69089997ee865",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the HF pipeline using Gemma 2B from Kaggle\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model='google/gemma-7b-it',\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    "    device='cuda',\n",
    "    max_new_tokens=512\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e809ca2259584341",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a teacher who teaches coding tests to users.\n",
    "You should explain the algorithm for the coding test problem to the user in detail.\n",
    "separate the steps but keep it detailed.\n",
    "Let's think step by step.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33e02fa3461fc3dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"{prompt}\\n\\n{example_yt_cc}\"\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f757d7ae8877ce32",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %%time\n",
    "# \n",
    "# prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "# outputs = pipe(\n",
    "#     prompt,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.1,\n",
    "#     top_k=5,\n",
    "#     top_p=0.3,\n",
    "#     add_special_tokens=True\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d78c627bbfb27d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# print(outputs[0][\"generated_text\"][len(prompt):])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54a2f787e4bbca0d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def summarize_example(text):\n",
    "    global prompt\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{prompt}\\n\\n{text}\"\n",
    "    }]\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    outputs = pipe(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        top_k=5,\n",
    "        top_p=0.3,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return outputs[0][\"generated_text\"][len(prompt):]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9e112068fae3d85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(summarize_example)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35bdb7311ee6918f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59e4c8535b7b92e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
