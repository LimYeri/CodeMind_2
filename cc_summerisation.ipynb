{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = datasets.load_dataset('kreimben/leetcode_with_youtube_captions')['train']\n",
    "df = df.to_pandas()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "462de18ad09c9d6f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the HF pipeline using Gemma 2B from Kaggle\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model='bert-large-uncased',\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    "    device='cuda',\n",
    "    max_new_tokens=512,\n",
    "    token=os.getenv('HF_API')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e809ca2259584341",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a teacher who teaches coding tests to users.\n",
    "You should explain the algorithm for the coding test problem to the user in detail.\n",
    "separate the steps but keep it detailed.\n",
    "let's think step by step.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33e02fa3461fc3dd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_execution_time = 0\n",
    "\n",
    "def summarize_example(text):\n",
    "    global prompt\n",
    "    print(f'Total Executed: {total_execution_time} times.')\n",
    "    \n",
    "    max_input_length = 512  # Reducing input length for stricter truncation\n",
    "    max_output_length = 512\n",
    "\n",
    "    chunks = [text[i:i + max_input_length] for i in range(0, len(text), max_input_length)]\n",
    "\n",
    "    summaries = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f'[CHUNK] {i + 1} / {len(chunks)}')\n",
    "        input_text = f\"{prompt}\\n\\n{chunk}\"\n",
    "        inputs = pipe.tokenizer(input_text, truncation=True, max_length=max_input_length, return_tensors=\"pt\")\n",
    "\n",
    "        # Ensure compatibility between output length and input constraints\n",
    "        max_new_tokens = min(max_output_length, max_input_length - len(inputs['input_ids'][0]))  \n",
    "\n",
    "        outputs = pipe(\n",
    "            input_text,\n",
    "            do_sample=True,\n",
    "            temperature=0.1,\n",
    "            top_k=5,\n",
    "            top_p=0.3,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            pad_token_id=pipe.tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        summary = outputs[0][\"generated_text\"]\n",
    "        summaries.append(summary)\n",
    "\n",
    "    return \" \".join(summaries)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9e112068fae3d85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "\n",
    "example = df[df['id'] == 1]['cc_content']\n",
    "example.sample(3)\n",
    "\n",
    "N = len(example)\n",
    "idx = random.randint(0, N)\n",
    "\n",
    "example_yt_cc = example.values[idx]\n",
    "example_yt_cc\n",
    "\n",
    "summarize_example(example_yt_cc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32c69089997ee865",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['summary'] = df['cc_content'].apply(summarize_example)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35bdb7311ee6918f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59e4c8535b7b92e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
