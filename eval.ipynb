{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import evaluate\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_id = 'kreimben/CodeMind-gemma'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('kreimben/CodeMind-gemma')\n",
    "tokenizer.padding_side = 'left'\n",
    "model = AutoModelForCausalLM.from_pretrained('kreimben/CodeMind-gemma')\n",
    "model = model.to('cuda')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "236cac5ab4f5ea47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "submission_dataset = datasets.load_dataset('kreimben/leetcode_user_submissions_only_python', split='train').to_pandas()\n",
    "submission_dataset = submission_dataset[['title_slug', 'question_hints', 'question_content', 'content']]\n",
    "captions_dataset = datasets.load_dataset('kreimben/leetcode_with_youtube_captions', split='train').to_pandas()[\n",
    "    ['title_slug', 'question_hints', 'question_content', 'cc_content']]\n",
    "captions_dataset.rename(columns={'cc_content': 'content'}, inplace=True)\n",
    "\n",
    "dataset = pd.concat([submission_dataset, captions_dataset])\n",
    "\n",
    "del submission_dataset, captions_dataset\n",
    "\n",
    "# dataset.head(3)"
   ],
   "id": "39f84a72b18f7b73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(dataset)"
   ],
   "id": "60ed82c09592134d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "GEMMA_2B_IT_MODEL_PREFIX_TEXT = \"\"\"Below is an coding test problem. Solve the question.\"\"\"\n",
    "\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"<start_of_turn>user {GEMMA_2B_IT_MODEL_PREFIX_TEXT}\\n\n",
    "I don't know {data_point['title_slug']} problem. give me the insight or appoach.\\n\n",
    "this is problem's hint.\\n{data_point[\"question_hints\"]}\\n\n",
    "here are some content of question.\\n{data_point[\"question_content\"]}<end_of_turn>\n",
    "<start_of_turn>model {data_point[\"content\"]}<end_of_turn>\"\"\""
   ],
   "id": "9775ff803f58cd46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_column = [generate_prompt(data_point) for data_point in dataset]\n",
    "dataset = dataset.add_column(\"prompt\", text_column)\n",
    "dataset = dataset.shuffle(seed=42)  # Shuffle dataset here\n",
    "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)"
   ],
   "id": "81f868a25ffb221a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset = dataset.remove_columns(['title_slug', 'question_hints', 'question_content', 'content', '__index_level_0__'])",
   "id": "62786a23ebe213af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds = dataset.train_test_split(test_size=.1)\n",
    "test_dataset = ds['test']"
   ],
   "id": "8cac76f53b94d8cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the fine-tuned model\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1_score[\"f1\"]}\n",
    "\n",
    "\n",
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    # args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ],
   "id": "39b50f0e1474d4ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluation_metrics = trainer.evaluate(eval_dataset=dataset, metric_key_prefix=\"test\")\n",
    "print(f\"Evaluation metrics: {evaluation_metrics}\")"
   ],
   "id": "6eef5a099ef539b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "21050442ce5a3c01",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
