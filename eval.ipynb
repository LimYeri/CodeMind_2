{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import evaluate\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import SFTTrainer\n",
    "import transformers\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_id = 'kreimben/CodeMind-gemma'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('kreimben/CodeMind-gemma')\n",
    "tokenizer.padding_side = 'left'\n",
    "model = AutoModelForCausalLM.from_pretrained('kreimben/CodeMind-gemma')\n",
    "model = model.to('cuda')\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "236cac5ab4f5ea47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "submission_dataset = datasets.load_dataset('kreimben/leetcode_user_submissions_only_python', split='train').to_pandas()\n",
    "submission_dataset = submission_dataset[['title_slug', 'question_hints', 'question_content', 'content']]\n",
    "captions_dataset = datasets.load_dataset('kreimben/leetcode_with_youtube_captions', split='train').to_pandas()[\n",
    "    ['title_slug', 'question_hints', 'question_content', 'cc_content']]\n",
    "captions_dataset.rename(columns={'cc_content': 'content'}, inplace=True)\n",
    "\n",
    "dataset = pd.concat([submission_dataset, captions_dataset])\n",
    "\n",
    "del submission_dataset, captions_dataset\n",
    "\n",
    "# dataset.head(3)"
   ],
   "id": "39f84a72b18f7b73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(dataset)"
   ],
   "id": "60ed82c09592134d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "GEMMA_2B_IT_MODEL_PREFIX_TEXT = \"\"\"Below is an coding test problem. Solve the question.\"\"\"\n",
    "\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"<start_of_turn>user {GEMMA_2B_IT_MODEL_PREFIX_TEXT}\\n\n",
    "I don't know {data_point['title_slug']} problem. give me the insight or appoach.\\n\n",
    "this is problem's hint.\\n{data_point[\"question_hints\"]}\\n\n",
    "here are some content of question.\\n{data_point[\"question_content\"]}<end_of_turn>\n",
    "<start_of_turn>model {data_point[\"content\"]}<end_of_turn>\"\"\""
   ],
   "id": "9775ff803f58cd46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds = dataset.train_test_split(test_size=.001)\n",
    "dataset = ds['test']\n",
    "del ds"
   ],
   "id": "8cac76f53b94d8cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_column = [generate_prompt(data_point) for data_point in dataset]\n",
    "dataset = dataset.add_column(\"prompt\", text_column)\n",
    "dataset = dataset.shuffle(seed=42)  # Shuffle dataset here\n",
    "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"], padding='max_length', truncation=True), batched=True)\n",
    "\n",
    "del text_column"
   ],
   "id": "81f868a25ffb221a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset = dataset.remove_columns(['title_slug', 'question_hints', 'question_content', 'content', '__index_level_0__'])",
   "id": "62786a23ebe213af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# Evaluate the fine-tuned model\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1_score[\"f1\"]}\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=None,\n",
    "    eval_dataset=dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        evaluation_strategy='epoch',\n",
    "        output_dir=\"out\",\n",
    "    ),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "id": "39b50f0e1474d4ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluation_metrics = trainer.evaluate()",
   "id": "6eef5a099ef539b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Evaluation metrics: {evaluation_metrics}\")",
   "id": "21050442ce5a3c01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d953273024b407fd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
