{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "peft_model_id = 'kreimben/CodeMind'\n",
    "revision_id = 'falcon-7b-20240404'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T07:02:42.420581Z",
     "start_time": "2024-04-04T07:02:42.409125Z"
    }
   },
   "id": "5d0841343288a663",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6a2882f69af4099a260ffe83244d95f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): FalconForCausalLM(\n      (transformer): FalconModel(\n        (word_embeddings): Embedding(65024, 4544)\n        (h): ModuleList(\n          (0-31): 32 x FalconDecoderLayer(\n            (self_attention): FalconAttention(\n              (rotary_emb): FalconRotaryEmbedding()\n              (query_key_value): lora.Linear(\n                (base_layer): FalconLinear(in_features=4544, out_features=4672, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4544, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4672, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (dense): FalconLinear(in_features=4544, out_features=4544, bias=False)\n              (attention_dropout): Dropout(p=0.0, inplace=False)\n            )\n            (mlp): FalconMLP(\n              (dense_h_to_4h): FalconLinear(in_features=4544, out_features=18176, bias=False)\n              (act): GELU(approximate='none')\n              (dense_4h_to_h): FalconLinear(in_features=18176, out_features=4544, bias=False)\n            )\n            (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n      )\n      (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n    )\n  )\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_id, revision=revision_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, revision=revision_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# model = model.to('cuda')\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T07:07:45.374705Z",
     "start_time": "2024-04-04T07:06:24.431278Z"
    }
   },
   "id": "da339336fd0fec2a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GenerationConfig {\n  \"bos_token_id\": 11,\n  \"eos_token_id\": 11\n}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T07:07:45.390085Z",
     "start_time": "2024-04-04T07:07:45.379848Z"
    }
   },
   "id": "b8fb3a0c91b85a3f",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "import time\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are a teacher who teaches coding tests to users.\n",
    "You should explain the algorithm for the coding test problem to the user in detail.\n",
    "separate the steps but keep it detailed.\n",
    "let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def formatting_func(user_input):\n",
    "    global system_prompt\n",
    "    return f\"<human>: {system_prompt}\\n\\n{user_input}\\n<assistant>: \"\n",
    "\n",
    "\n",
    "def generate_response(user_input):\n",
    "    user_input = formatting_func(user_input)\n",
    "\n",
    "    inputs = tokenizer(user_input, return_tensors='pt')\n",
    "    input_ids = inputs['input_ids']#.to('cuda')\n",
    "    \n",
    "    tic = time.time()\n",
    "\n",
    "    generation_config = GenerationConfig(\n",
    "        penalty_alpha=.6,\n",
    "        do_sample=True,\n",
    "        top_k=5,\n",
    "        temperature=.5,\n",
    "        repetition_penalty=1.2,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=256\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'time': time.time() - tic,\n",
    "        'responses': generation_output.sequences,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T07:07:45.405447Z",
     "start_time": "2024-04-04T07:07:45.390085Z"
    }
   },
   "id": "initial_id",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    res = generate_response('leetcode no.1 add sum. explain me')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:25:26.323629Z",
     "start_time": "2024-04-04T07:07:45.407524Z"
    }
   },
   "id": "53e5cc4048cd7b7b",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[   39, 15564, 48190,   204,   193,  1357,   362,   241,  6092,   569,\n         15864, 16958,  5918,   271,  2826,    25,   193,  1357,   808,  5656,\n           248, 12910,   312,   248, 16958,  1318,  1375,   271,   248,  2735,\n           272,  3730,    25,   193, 28062,   375,   248,  4128,   480,  1244,\n           334,  6626,    25,   193,  1025,    18,    94,   864,  2006,   431,\n          2006,    25,  1001,   193,   274,   289,  5779,   658,    25,    28,\n           737,  8370,    25,  5656,   454,   193,    39,   524,  7893, 48190,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258,   500,   204,    70,\n         19426,    72,   258,   500,   204,    70, 19426,    72,   258,   500,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258,   500,   204,    70,\n         19426,    72,   258,   500,   204,    70, 19426,    72,   258,   500,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258,   500,   204,    70,\n         19426,    72,   258,   500,   204,    70, 19426,    72,   258,   500,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258,   500,   204,    70,\n         19426,    72,   258,   500,   204,    70, 19426,    72,   258,   500,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258,   500,   204,    70,\n         19426,    72,   258,   500,   204,    70, 19426,    72,   258,   500,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258,   500,   204,    70,\n         19426,    72,   258,   500,   204,    70, 19426,    72,   258,   500,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258,   500,   204,    70,\n         19426,    72,   258,   500,   204,    70, 19426,    72,   258,   500,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258,   500,   204,    70,\n         19426,    72,   258,   500,   204,    70, 19426,    72,   258,   500,\n           204,    70, 19426,    72,   258,   500,   204,    70, 19426,    72,\n           258,   500,   204,    70, 19426,    72,   258]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['responses']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:25:26.474157Z",
     "start_time": "2024-04-04T14:25:26.354275Z"
    }
   },
   "id": "4187876464676729",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "raw_model_id = \"tiiuae/falcon-7b\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=raw_model_id,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a647fdf32ce06f6f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%time\n",
    "sequences = pipeline(\n",
    "    \"leetcode no.1 add sum. explain me\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "801f8cc105e853fb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3ada330e6ad40491",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
